project_list:
- abstract: "Interpretation of CNV data is challenging. This is mainly due to the\
    \ large number of potential CNV events initially called in the analysis of a given\
    \ biological sample, but especially due to a lack of a high-quality open reference\
    \ database for CNV representing a \"normal background\" w/o disease association\
    \ in the general population.\n\nIn response to this challenge, we propose to build\
    \ an open reference resource for human CNV, that will include publicly available\
    \ datasets from which CNV positions will be gathered. We will start using a prototype\
    \ developed within the ELIXIR hCNV community group, work on making this \u201C\
    Proof of Concept\u201D openly available (guidelines from ELIXIR Tools, https://elixir-europe.org/platforms/tools/software-best-practices)\
    \ to facilitate contributions from users from other communities, identify and\
    \ increase the number of datasets to integrate, deploy data wrappers for import\
    \ and upload of data compliant with the latest file format standards (e.g. VCF\
    \ 4.4; GA4GH BED 1.0); include data discovery and exchange functionalities based\
    \ on the latest recommendations from international initiatives (e.g. Beacon v2,\
    \ GA4GH VRS 1.3) and create connectors to facilitate its use through home-made\
    \ workflows as well as Galaxy instances.\n\nImportantly, the project will for\
    \ the first time combine recent standard developments relevant to CNV data, especially\
    \ with respect to VCF4.4, VRS 1.3 and Beacon v2.n, and provide computational tools\
    \ for standards conform handling of CNV data to the ELIXIR communities and beyond."
  authors: David Salgado, Krzysztof Poterlowicz, Michael Baudis
  extra_info: 'Last year, hCNV community members started prototyping such a resource,
    designing the database structure and collecting CNV from the 1KGP Dragen reanalysis
    initiative. Tasks for this project will be to:

    - Adapt the prototype, to make it generic

    - identify new datasets to include

    - Create API connections to other public data resources for CNV (Progenetix, Decipher,
    EBI EVA, GnomAD)

    - develop uploaders/exporters to facilitate and automate data import/export from
    VCF (new specifications for CNV/SV), and others ELIXIR and GA4GH data format and
    exchange formalism (BED)

    - Make the datasets discoverable through Beacon v2

    - Create data connector with Galaxy instances for data exploration

    - Project outputs (data code) will be made available under the maximally permissive
    licence in a git repository to encourage contribution and sustainability and communicated
    through the cnvar.org website and additional channels.

    Is welcome any person with interest in any of the fields that are relevant for
    this project'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/1
  number: null
  project_number: 1
  title: "A \u201Cbatteries-included\u201D open reference resource for human genomic\
    \ copy number variants (CNV)"
- abstract: "This project aims to generate genomic synthetic data and to guarantee\
    \ the privacy and safety of sensitive private data. This is a hot topic and every\
    \ day there are published new more sophisticated generators and infrastructure\
    \ has already been provided during last year\u2019s BH22 for the community, where\
    \ we focused on clinical data. Now the current challenge is quality and privacy\
    \ of the generated synthetic data. We need metrics to assess this in a transparent\
    \ and systematic way.\n\nHowever, there is not a current consensus in the community\
    \ on what evaluation metrics to use to check the quality and privacy of generated\
    \ synthetic datasets for health research such as for genomics or phenomics analyses,\
    \ which is KEY for benchmarking (like the effort from openEBench), and for the\
    \ downstream application like the case of variant calling where there is a need\
    \ for ground truth datasets with which one can compare and asses their results.\n\
    \nParticipants will form two groups: the generation group and the benchmarking\
    \ group and will work in parallel. In this way they will learn about the generation\
    \ of synthetic data and the importance of accurately capturing the characteristics\
    \ of real-world data. Participants will also learn about the limitations and biases\
    \ of different generative models, the importance of evaluation indicators, benchmarking\
    \ variant calling algorithms and how they can affect their performance.\n\nOverall,\
    \ the proposed project will provide an exciting opportunity to explore the use\
    \ of synthetic data in life sciences and also connect with previous ELIXIR efforts."
  authors: "Styliani-Christina Fragkouli, Alberto Labarga, N\xFAria Queralt Rosinach"
  extra_info: "Focus: to promote the use of synthetic data, set evaluation best practices,\
    \ connect with efforts of ELIXIR ML Focus Group.\n\nExpected outcomes:\n\n 1.\
    \ Identify a list of genomics and phenomics metrics, (short term)\n    \n    \n\
    \ 2. suggest evaluation best practices, (short term),\n    \n    \n 3. BioHackrXiv\
    \ paper (short term),\n    \n    \n 4. introduce practices and metrics viz in\
    \ the infrastructure developed last year BH-EU or/and in OpenEBench, to be used\
    \ by the ELIXIR community, (long term)\n    \n    \n 5. expand the project scope\
    \ including additional variant callers and synthetic data generators (long term)\n\
    \    \n    \n 6. Paper(long term)\n    \n    \n\nWe plan to spend the 5-days BH\
    \ to provide the first three outcomes, start designing and implementing the fourth,\
    \ and discuss the fifth.\n\nRequired expertise: python/R developer(s) with experience\
    \ in data science, Synthetic data experts and users, Researcher(s) with experience\
    \ in variant calling and/or statistics/ML.\n\nTools: generating (NEAT, ART) and\
    \ variant calling (GATK, VarScan) algorithms."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/2
  number: null
  project_number: 2
  title: 'Assessing quality and privacy metrics of synthetic health data for benchmarking:
    the variant callers use case.'
- abstract: 'Pollinators are essential to food production as about 75% of our world''s
    food crops depend at least in part on pollination. Yet as the European Red List
    of Bees and other sources highlight, more than 50% of the European bee species
    are currently data deficient, and as a consequence, a Red List status (e.g. threatened,
    endangered, vulnerable) cannot be assigned. This means that there are probably
    many more bee species threatened in Europe on top of the 9% that were assessed
    as such so far.


    However, bees in particular are hard to identify. This leads to underrepresentation
    on resources such as Global Biodiversity Information Facility (GBIF), a Global
    Core Biodata Resource (GCBR). GBIF aggregates metadata on many if not all known
    species from various crowd sourcing initiatives. On one of these platforms, iNaturalist.org,
    58% of the European bee species have already been recorded, making citizen scientists
    an important source for observational data on pollinator species. Through better
    and more accessible species identification tools, the quantity and quality of
    these observations could be significantly improved. Books written by experts are
    available for some regions, and there are also physical reference collections
    in some museums. Additionally, a lot of the information on pollinators is scattered
    over the internet.


    During this hackathon, we aim to develop a virtual reference collection that can
    act as a central hub of taxonomic data needed for feature detection, enabling
    large communities of naturalists to recognize and, by doing so, help identifying
    the state of our pollinators.'
  authors: "Sofie Meeus, Maria Heikkil\xE4, Andra Waagmeester"
  extra_info: 'By the end of the hackathon, we want to present a demo of an accessible
    and useful virtual reference collection. This mock-up will then feed into the
    TETTRIs project that aims to build a virtual pollinator reference collection for
    all European pollinators.

    Our main focus will be on the types of data that are needed for insect identification
    mentioned above. We will focus on finding and storing links between different
    open databases (e.g. GBIF, BOLD, ENA, GloBI) into a Wikibase for, for example,
    bees. These links will then be leveraged into new or improved Wikipedia articles
    that could help citizen scientists with their identifications.

    For the project to succeed, we need a diverse team of around 7 people who will
    contribute at a range of different levels from writing scripts to extracting verified
    specimens from global infrastructures to validating outputs, assembling species
    profiles, verifying taxonomy and linking additional information.'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/3
  number: null
  project_number: 3
  title: Automating the building of a virtual, distributed pollinator reference collection.
- abstract: "Benchmarks - standardized tests comparing performance, accuracy, and\
    \ efficiency - are key for evaluating individual tools and composite workflows.\
    \ In a \u201CBake Off\u201D setting, they allow for comparisons of candidate tools\
    \ and workflows for a particular computational task in order to determine the\
    \ best-performing one. In this BioHackathon project, we will conduct a \u201C\
    Great Bake Off of Bioinformatics Workflows\u201D to assess the effectiveness of\
    \ existing workflow-level benchmarks and develop further ideas. We will invite\
    \ BioHackathon participants to share tools and workflows with us, and collect\
    \ their feedback and further ideas for benchmarks. Initially, the benchmarks will\
    \ be tested in the proteomics domain due to mature domain annotations and project\
    \ lead expertise. The participants' areas of expertise will guide the exploration\
    \ of additional domains.\n\nIn recent and ongoing work in ELIXIR Implementation\
    \ Studies and spin-off projects, we have already developed several rudimentary\
    \ workflow-level benchmarks for bioinformatics data analysis pipelines, including\
    \ those automatically composed by the APE (Automatic Pipeline Explorer; https://github.com/sanctuuary/APE)\
    \ framework. Before deploying these benchmarks for production use, however, their\
    \ definitions must be aligned with benchmarks at the tool-level and formalized.\
    \ This process should prioritize benchmarks that are most relevant for users when\
    \ selecting, comparing, and deploying workflows for daily use. The BioHackathon\
    \ project will consolidate these efforts by bringing together people with complementary\
    \ expertise and bridging ongoing ELIXIR efforts to (1) produce a minimum fit-for-purpose\
    \ set of workflow-specific benchmarks, (2) test and evaluate these in real-world\
    \ examples and (3) create a repository for continuing the development of these\
    \ benchmarks beyond the BioHackathon."
  authors: Vedran Kasalica, Magnus Palmblad, Anna-Lena Lamprecht
  extra_info: 'The Project builds on a simple set of workflow benchmarks. Users and
    developers of bioinformatics software, computer scientists and software engineers
    can all contribute, without expertise in any particular bioinformatics domain.
    Five to six participants are needed for the Project to succeed.


    Short-term, the Project will deliver a draft of defined workflow-level benchmarks,
    each with examples and defined relationships to existing tool-level benchmarks
    and standards. We will systematically discuss the different types of workflow-level
    benchmarks, including both design-time (algorithmic complexity, workflow deployability)
    and run-time (performance metrics). The leads will ensure all important types
    of benchmarks are discussed. Draft benchmark definitions and examples will be
    revisited at the end of the BioHackathon.

    Long-term, these benchmarks will be implemented in the Workflomics project, run
    by the Project Leads, and ongoing Proteomics Implementation Studies. These workflow-level
    benchmarks will be carefully documented and shared with the community in publications
    and talks in relevant fora.'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/4
  number: null
  project_number: 4
  title: Benchmarks for Bioinformatics Workflow Bake Offs
- abstract: "During the Biohackathon we want to work on metadata for publications\
    \ in the context of BioHackrXiv.org - the markdown based pre-publishing biohackathon\
    \ platform for project reporting that is used by a handful of biohackathons every\
    \ year, including the Elixir and Japanese biohackathons. This has resulted in\
    \ over 40 publications, so far, with 200+ authors. The number of submissions is\
    \ increasing every year.\n\nIn previous years we worked on improved support for\
    \ publications, including an improved preview/PDF generation experience and CiTO\
    \ support. Also we mapped out future work for BioHackrXiv in this unpublished\
    \ [doc](https://github.com/biohackrxiv/bhxiv-metadata/blob/main/doc/elixir_biohackathon2022/paper.md)\
    \ where we want to improve metadata handling and the publishing system itself.\
    \ These are obvious topics to work on during the Elixir biohackathon 2023.\n\n\
    A full list of supported hackathons can be found [here](http://preview.biohackrxiv.org/)\
    \ and a list of publications [here](https://biohackrxiv.org/discover).\n\nPrevious\
    \ publications are [here](https://biohackrxiv.org/discover?q=biohackrxiv).\n\n\
    \ * Arun Isaac\n * Tazro Ohta\n * Egon Willighagen\n * Toshiaki Katayama\n * Gianluca\
    \ Della Vedova (remote)\n * Pjotr Prins"
  authors: Pjotr Prins, Tazro Ohta, Arun Isaac
  extra_info: Long term project has been going for years. For plan see abstract above.
    We would like to be with 2 active team members (Pjotr & Arun) on-site to be able
    to write code. We will have at least one remote participant (Gianluca) and other
    experts that are likely in other biohackathon groups (Egon, Tazro, Toshiaki).
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/5
  number: null
  project_number: 5
  title: BioHackrXiv and publications
- abstract: 'Machine Learning (ML) models are scattered across various resources without
    sufficient metadata, making them difficult to find, access, and reuse. Additionally,
    the lack of standards and interoperability in ML formats and programming frameworks,
    along with dependencies on multiple software libraries, make reproducing ML models
    a resource-intensive task. BioModelsML project aims to develop a comprehensive
    collection of FAIR and reproducible ML models for re-use in life science and medical
    research.

    BioHackEU22#9 and continuous team effort have paved the way to develop a FAIR-ML
    checklist and workflows covering aspects such as training code, trained model
    sharing, dataset linking, figure reproduction, evaluation metrics, Docker for
    building and applying trained ML models, model metadata, and dissemination via
    BioModels. We are currently working on several reference ML models to demonstrate
    application of checklist and workflows.

    In BioHackathon2023, we aim to invite ML modellers and software developers (both
    onsite and virtual) to curate and disseminate ML models via BioModels using our
    FAIR-ML checklist. We will use interactive hacking sessions to improve our checklist
    and prepare documentation for community curation. Through interaction with the
    EDAM and BioSchemas teams, we will improve metadata annotation aspects and align
    our checklist with the DOME guidelines.

    This proposal addresses a grand challenge and has the potential to have a huge
    impact on the field. The BioHackathon2023 will help us finalize key aspects of
    FAIR ML model curation and dissemination via BioModels and provide enough pilot
    work to apply for the needed large national or international funding to drive
    this project.'
  authors: Rahuman Sheriff, Nils Hoffmann, Sumukh Deshpande
  extra_info: 'Our short team goal is to refine our current FAIR-ML checklist and
    workflow to share a small collection of metadata-rich reproducible ML models via
    BioModels within six months. Our long-term goal is to build an open and free collection
    of FAIR reproducible ML models in BioModels through internal and community curation.

    In the BH2023, we will revise the FAIR-ML checklist and workflows through community
    engagement with ML modellers to gather their feedback as well as support them
    to disseminate their models through BioModels.

    We will engage with the BioCuration, BioSchemas, EDAM, DOME, APICURON and the
    ML community to align our project. Specifically, we will try to establish the
    minimal metadata required to annotate ML models and the required ontologies with
    members of ELIXIR ML group.

    The team consists of eight on-site and remote members, including leads. We will
    try to recruit at least three additional ML/domain experts.'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/6
  number: null
  project_number: 6
  title: 'BioModelsML: Building a FAIR and reproducible collection of machine learning
    models in life science and medicine for easy reuse'
- abstract: Bioschemas is a community-based effort providing specifications, tools
    and training on how to add structured markup on webpages in Life Sciences. Although
    Bioschemas main aim is to facilitate findability, it also provides an initial
    interoperability layer. To achieve this, Bioschemas recommends the use of EDAM
    terms and other ontologies whenever it fits. Bioschemas has been successfully
    implemented across different communities inside and outside ELIXIR; the plant
    and chemistry communities are two examples. In this project, we want to create
    a knowledge graph of plant resources and extract a resource index showing the
    use of ontology terms. This preliminary analysis will allow us to understand better
    how Bioschemas markup is currently used in these two communities so we can take
    actions to improve the markup and therefore interoperability across resources.
    Thanks to the use of the markup extraction tool, FAIR Checker, we will also get
    a FAIR assessment of the Bioschemas markup as well as the validity of it (wrt
    to Bioschemas profiles). We will also get insights on how external vocabularies
    are used, whether consistently or not (one more opportunity of improvement). This
    project builds upon previous work done by the IDP Community in aggregating Bioschemas
    markup and constructing the IDP knowledge graph, which served as the basis for
    the IDPcentral registry. Results will also be helpful for the Bioschemas community
    as a proof-of-concept approach on Bioschemas consumption.
  authors: "Steffen Neumann, Daniel Arend, Ivan Mi\u010Deti\u0107"
  extra_info: 'The short-term goal during the Hackathon is an assessment of available
    markups and pipeline implementation, while the longer-term goal is to engage the
    communities for maintenance and increased adoption. Incremental prototyping will
    be performed on the data provider, harvesting and knowledge graph sides.

    During the BioHackathon, participants will become familiar with knowledge graphs,
    such as those used by the FAIR Checker. Selected analyses will be implemented,
    including assessments of resource FAIRness, use of external ontologies, and consistency
    checks (e.g., a data catalog should contain at least one dataset).

    The project requires a minimum of 4 participants, ideally 6 or more. Participants
    should have knowledge in one or more of the following areas: JSON+LD/Bioschemas
    markup, knowledge graphs, SPARQL, Python. At least one co-lead will be on-site
    and one online, with at least two developers and support for SPARQL queries. Minimal
    support from FAIR Checker developers is also sought.'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/7
  number: null
  project_number: 7
  title: Bioschemas resource index for chem and plants
- abstract: "ELIXIR recognizes the importance of effective software management in\
    \ enabling sustainable and reproducible research outcomes. The Software Best Practices\
    \ group, part of the ELIXIR Tools Platform, is actively working towards providing\
    \ a framework for creating Software Management Plans (SMPs) in ELIXIR. SMPs are\
    \ crucial for ensuring that research software is developed, maintained, and shared\
    \ in a structured manner that aligns with industry best practices. However, creating\
    \ SMPs can be a time-consuming and daunting task, especially for researchers without\
    \ prior experience in software development or management. Moreover, it is equally\
    \ important to ensure that any produced SMP can be effectively used in an automated\
    \ way, i.e. incorporate the appropriate metadata.\n\nTo address this challenge,\
    \ we are proposing a cutting-edge project with the following objectives:\n\n 1.\
    \ streamline the process of creating SMPs for research software in ELIXIR by developing\
    \ the necessary integrators,\n 2. identify and review the appropriate metadata\
    \ schema, also in connection to relevant initiatives (OpenEBench, FAIR4RS, RDA,\
    \ maSMPs etc).\n\nUltimately, the developed solution will be tailored to the unique\
    \ needs of ELIXIR Communities while being flexible for adoption outside ELIXIR,\
    \ aiming to provide a smart, efficient and user-friendly way to develop SMPs.\
    \ Moreover, with a streamlined approach to creating SMPs, we aim to facilitate\
    \ efficient management of research software, improve the quality and reproducibility\
    \ of research results, and promote best practices in software management, within\
    \ ELIXIR and beyond. Furthermore, our project will contribute to the continued\
    \ success of ELIXIR in integrating and harmonizing biological data resources and\
    \ tools across Europe."
  authors: "Eva Martin del Pico, Marek Such\xE1nek, Renato Alves"
  extra_info: The team working on this project will have both content and technical
    expertise to work on the proposed deliverables but external feedback is always
    welcome. It is expected that at least the listed items 1-4 will be ready for use
    by the end of the hackathon. For a successful hacking week we would require at
    least 2 people from the Software Best Practices team and 2 people from the Data
    Stewardship Wizard team. Generic programming skills are required. Knowledge of
    the Jinja2 framework is helpful. After the hackathon, we will disseminate the
    results in a BioHackRXiv report and we will collect feedback from real-world use
    cases. By the end of 2024, we expect to fine-tune the results and include them
    in the ELIXIR Annual report.
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/8
  number: null
  project_number: 8
  title: Building towards a machine-actionable Software Management Plan
- abstract: 'During previous BioHackathons, we established computational workflows
    connecting ELIXIR resources for systems biology molecular analyses. Extending
    our previous work, we will facilitate the construction and use of advanced pathway
    models to investigate novel therapeutics.

    Normally gene-drug associations are determined at the bulk level, not considering
    cell-type specificity. We will use single-cell data to establish dedicated pathway
    and disease maps, and connect them to the HiPathia and other modeling tools and
    approaches. With this, we will find cell types in which druggable targets are
    uniquely expressed. The process of visual model construction will be coupled with
    dedicated training materials describing the refinement process of automatically
    combined diagrams.

    In our project, we will use publicly available single cell data or resources suggested
    by the Single Cell Omics (SCO) Community. Genes differentially expressed in specific
    cell types will be used to fetch the content of pathway databases - Reactome (ELIXIR
    Core Data Resource) and WikiPathways (ELIXIR-NL service) - and disease maps (a
    service of ELIXIR Luxembourg Node). These diagrams will be assembled into a single
    resource, and enriched against compounds in DrugBank, ChEMBL and OpenTargets.
    Such a resource will be available for systems biology analysis and modeling. This
    way, a disease pathway map will be set up, containing druggable mechanisms specific
    for cell types specified by scRNASeq data. This workflow will be reproducible
    and applicable for other scRNASeq data, bringing together a number of ELIXIR resources
    and communities, and support the developing Systems Biology and SCO Communities.'
  authors: Marek Ostaszewski, Martina Summer-Kutmon, Naveed Ishaque
  extra_info: "Short-term goal is to establish a prototype of the pipeline for two\
    \ selected datasets and its documentation (up to a month after the BH2023)\n\n\
    Long-term goals are (up to a year after the BH2023):\n\n * Establish the prototype\
    \ into a reproducible pipeline\n   \n   \n * Extend the list of use-cases to three\
    \ sets of novel results\n   \n   \n * Prepare a publication\n   \n   \n\nThe focus\
    \ will be on completing an end to end solution, reducing the scope of used drug\
    \ databases and pathway resources where necessary. We will likely establish three\
    \ groups, working on i) data, ii) workflow and iii) user specifications and documentation.\
    \ We will have daily project updates and the groups will be working in parallel\
    \ but in contact.\n\nMinimum nb of people: 6 (already committed)\n\nExpertise:\
    \ R, Python, JavaScript (workflow, data), pathway databases, systems biology standards\
    \ (specs, documentation)\n\nMethodology: Seurat, systems biology format conversions,\
    \ disease maps, pathway databases, drug target analysis"
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/9
  number: null
  project_number: 9
  title: Cell type-specific and druggable pathway models and maps
- abstract: "Single-cell analysis has emerged as a powerful tool in the study of complex\
    \ biological systems, but there are currently no standardized platforms for evaluating\
    \ the accuracy and reproducibility of the wide array of computational tools and\
    \ workflows. Benchmarking is critical for identifying and addressing the limitations\
    \ of single-cell analysis tools and workflows, as well as for comparing the performance\
    \ of different methods. Community engagement in the benchmarking process is important,\
    \ as it enables researchers, both end-users and methods developers, to share their\
    \ data, software, and expertise to improve the quality of reference datasets and\
    \ evaluation metrics. However, current benchmarking efforts for single-cell analysis\
    \ methods are mostly static and do not support easy extension and updating, a\
    \ critical need given the fast pace at which new methods are developed.\n\nA recent\
    \ article in Nature (https://www.nature.com/articles/d41586-022-04426-5) highlights\
    \ the need to address this issue via implementation of single-cell benchmarking\
    \ via the OpenEBench (https://openebench.bsc.es) and OMNIBENCHMARK (https://omnibenchmark.org/)\
    \ platforms. These platforms provide a framework for curating reference datasets,\
    \ algorithms, and workflows for single-cell analysis, with a view towards extensibility\
    \ as new computational approaches emerge. These two platforms share some commonalities,\
    \ yet cater for different target audiences and benchmarking strategies.\n\nOur\
    \ proposal aims to address these issues by assembling motivated benchmarking-minded\
    \ computational biologists to push forward existing and new \u201Ccontinuous\u201D\
    \ benchmarking efforts."
  authors: Ahmed Mahfouz, Mark Robinson, Salvador Capella-Gutierrez
  extra_info: "Timeline:\n\n * Prepare (data wrangling, organizing speakers, advertising)\
    \ [2-4 month before BH]\n   \n   \n * Establish a benchmark in OMNIBENCHMARK [during\
    \ BH]\n   \n   \n * Report experiences and findings in biohackRxiv [6 weeks after\
    \ BH]\n   \n   \n * Encourage externals to contribute to the SCO OMNIBENCHMARK\
    \ [Q1 2024]\n   \n   \n * Write article outlining the landscape of systematic\
    \ benchmarking platforms for SCO in collaboration with OpenEBench [Q1 2024]\n\
    \   \n   \n\nParticipants:\n\nWe aim to attract 12 or more participants. We will\
    \ divide the participants into small working groups: data, methods, and evaluation\
    \ measures. The minimum requirement to participate is some familiarity with all\
    \ of the following: command line, GitLab CI/CD, docker, Python, and R.\n\nSchedule:\n\
    \nProf. Robinson hosted two (hybrid) hackathons for OMNIBENCHMARK (a 2-full-days\
    \ format). We will extend this setup (lectures, hacking, feedback, and hotfixes)\
    \ to 1 day of onboarding/training, 2 full days of hacking on the system, and a\
    \ 1 multi-faceted day to continue hacking and interface with connections to OpenEBench."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/10
  number: null
  project_number: 10
  title: Community-driven continuous benchmarking of single-cell tools
- abstract: "Since June 2022, in ELIXIR-CONVERGE, hackathons-style events have been\
    \ organised with the (beyond life sciences) community to develop FAIR lesson plans.\
    \ Community-led, open lesson plans originate from the 2021 FAIRsFAIR training\
    \ handbook, addressing competencies, training designs and 16 lesson plans.\n\n\
    We aim to provide a consistent approach for FAIR training. Focus is the shared\
    \ foundations and learning paths critical for long-term FAIR data sustainability.\
    \ Although lesson plans aren\u2019t ready-to-go courses yet, they offer the framework\
    \ and the basis for FAIR training. A community-led exercise helps to harmonise\
    \ FAIR training efforts and create a basis for the implementation of FAIR data\
    \ in local organisations: what do researchers, data stewards, other data experts\
    \ have to be skilled in to apply FAIR in projects and to datasets?\n\nThis community\
    \ effort to create cross-domain FAIR lesson plans is highly innovative, as most\
    \ local organisations regardless of the discipline struggle with training about\
    \ the FAIR principles in practice (how do you go/do FAIR). Such an aim reaches\
    \ beyond the efforts of ELIXIR-CONVERGE, potentially even beyond ELIXIR. The challenge\
    \ is to identify and incorporate relevant training materials from national and\
    \ local contexts and cross-domain/domain-agnostic resources into lesson plans.\n\
    \nThe main activity of this Biohackathon project is to review and expand the current\
    \ lesson plans. We will discuss the need and scope of the lesson plans collection,\
    \ collectively write new lesson plans, and inspire on integrating lesson plans\
    \ into local training programs. We think this Biohackathon project stimulates\
    \ novel collaborations in data FAIRification training."
  authors: Stephan Nylinder, Martijn Kersloot, Mijke Jetten
  extra_info: "All contributors from and beyond ELIXIR are invited to bring in their\
    \ expertise, regardless of academic qualification. There is no minimum or maximum\
    \ number. The lesson plan format was chosen as it was used in FAIRsFAIR as well\
    \ and it works so far for community members.\n\nShort-term goals (during BioHackathon)\n\
    \n * Gained insight into existing materials aimed towards researchers and data\
    \ managers, specifically focused on FAIR data management\n * Added relevant elements\
    \ from those materials to existing lesson plans\n * Have created content for new\
    \ lesson plans, as well as extended existing ones, f.i. for a new audience\n *\
    \ Published the updated and new lesson plans via the Training Platform Github\n\
    \ * Integrated lesson plans into learning paths for various stakeholders\n\nLong-term\
    \ goals (half a year after the BioHackathon):\n\n * Established an editorial board\
    \ as part of the emerging ELIXIR RDM Community\n * Created a sustainability plan\
    \ as part of the emerging ELIXIR RDM Community"
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/11
  number: null
  project_number: 11
  title: Creating lesson plans to advance (life sciences) data steward & researcher
    FAIR skills
- abstract: "This project will develop the ELIXIR DS/DM Handbook to provide guidance\
    \ on organising DS/DM activities in life sciences. The Handbook benefits DS/DM,\
    \ including the emerging ELIXIR RDM Community (open to academia and industry beyond\
    \ ELIXIR), offering a reference point and inspiration to develop their network\
    \ and capacity.\n\nIn September 2022, attendees at the ELIXIR-CONVERGE WP1 Padua\
    \ meeting raised the need for the Handbook. Starting in April 2023, three pilot\
    \ chapters are in progress: (1) how to build a community, (2) DM/DS profiles,\
    \ competencies and career paths, (3) an ELIXIR RDM maturity model/services profile.\
    \ The Handbook format was chosen for its practical application, and motivating\
    \ DS/DM to share experiences, preventing reinventing the wheel and siloed development\
    \ in local organisations.\n\nThe Handbook is life-science focused with potential\
    \ to expand to other disciplines. It differs from others due to its open access\
    \ and community-led aspects, including best practices and community profile examples.\
    \ It\u2019s not a guide for providing training, nor a resource on data management\
    \ (as there is RDMkit, FAIR Cookbook, DSW). The main activity is producing consensual\
    \ goals and scope for the Handbook, then reviewing and expanding content accordingly,\
    \ and prototyping the handbook as an online resource to maximise its openness\
    \ and use.\n\nThis proposal is co-written by the following people who will be\
    \ involved in organising the project: Martin Cook (ELIXIR-HUB), Pinar Alper (ELIXIR-LU),\
    \ Krzys Poterlowicz (ELIXIR-UK), Robert Andrews (ELIXIR-UK), Munazah Andrabi (ELIXIR-UK),\
    \ Brane Leskosek (ELIXIR-SL)."
  authors: Mijke Jetten, Nazeefa Fatima, Xenia Perez Sitja
  extra_info: "At the end of the BioHackathon, we have:\n\n * Defined the use of the\
    \ Handbook for the DS/DM community in the context of activities, tools and services,\
    \ in and beyond ELIXIR\n * Decided on the landing place for the Handbook to maximise\
    \ its openness,\n * Added cross-links to communities and sections of RDMkit, FAIR\
    \ Cookbook, DSW etc.\n * Reviewed content and created content based on needs and\
    \ experiences\n * Created a sustainability plan as part of the emerging ELIXIR\
    \ RDM Community\n\nWithin six months after the BioHackathon, we have:\n\n * Published\
    \ a first version Handbook\n * Established an editorial board as part of the emerging\
    \ ELIXIR RDM Community\n\nAll DS/DM from and beyond ELIXIR are invited to bring\
    \ in their expertise, regardless of academic qualification. There is no minimum\
    \ or maximum number. The Handbook format was chosen for its practical application,\
    \ motivating DS/DM to share experiences."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/12
  number: null
  project_number: 12
  title: Creating the ELIXIR Data Stewardship/Management (DS/DM) Handbook - a guide
    for DS/DM to manage their life sciences RDM efforts
- abstract: 'Software Heritage is currently the largest archive of software in source
    code form, hosting more than 14,000,000,000 source files and 223,000,000 projects.
    It regularly crawls data from 18 different software platforms such as Github or
    Gitlab, storing the code of the vast base of developers and organizations nowadays.
    These sources are used not only for software development, but also for open-source
    projects, documentation, and other types of collaborative projects. Bioinformatics
    software is no exception when it comes to hosting source code on these platforms.
    Around 60% of software in bio.tools respectively has an associated repository.
    However, many softwares hosted in these repositories are still not registered
    in commonly used registries.

    In this project, we will build a software prototype that identifies whether a
    repository is hosting Bioinformatics Software. We will use Software Heritage API
    to search for repositories and a combination of strategies, involving NLP and
    machine learning techniques, to analyze the text in the repository''s README and
    other relevant files, including source code ones. And determine if they can be
    categorized as bioinformatics software. To do so, we will take advantage of the
    curated data gathered in OpenEBench Tools Monitoring/Software Observatory, which
    currently monitors over 9,300 bioinformatics tools with an assigned (or valid)
    GitHub repository.

    This implementation would allow us to discover thousands of tools and services,
    and add them to the EXILIR Tools Ecosystem, making them more findable for the
    wider community.'
  authors: "Eva Martin del Pico, Sergi Aguil\xF3-Castillo"
  extra_info: "In the short-term we would like to rescue repositories that are not\
    \ found in any software repository. In the long-term, incorporate the software\
    \ into the OpenEBench tools monitoring ecosystem to continuously push new tools\
    \ to either the ELIXIR Tools Ecosystem or to human reviewers for validation.\n\
    \nActivities during the Biohackathon will be:\n\n * Using the Software Heritage\
    \ API to extract the data we need, including repositories content and tags. We\
    \ will focus on repositories from GitHub, and then GitLab in case of successful\
    \ results.\n   \n   \n * Defining and prioritizing strategies (NLP, ML, etc) to\
    \ determine if a repository contains bioinformatics software. We will preferentially\
    \ but not exclusively rely on README and documentation for the inference.\n  \
    \ \n   \n * Implementation of the strategies by participants.\n   \n   \n\nWe\
    \ think that we need around 4-5 people full-time to work on the project. We welcome\
    \ participants with at least basic expertise in APIs, Machine Learning, NLP, and\
    \ software metadata."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/13
  number: null
  project_number: 13
  title: Discovering Bioinformatics Software in Software Heritage
- abstract: 'A prevailing paradigm in Research Data Management (RDM) is to publish
    research datasets in designated archives upon conclusion of a research process.
    However, it is beneficial to abandon the notion of "final" or "static" data artifacts
    and instead adopt a continuous approach towards working with research data, where
    data is constantly archived, versioned, and updated. This "immutable yet evolving"
    perspective allows for the application of existing technologies and processes
    from software engineering, such as continuous integration, release practices,
    and version management backed by decades of experience, and adaptable to RDM.

    To facilitate this, we propose the Annotated Research Context (ARC), a data and
    metadata layout convention based on the well-established ISA model for metadata
    annotation and implemented as Git repositories. ARCs are amenable towards frequent,
    lightweight data management operations, such as (meta)data validation and transformation.
    The Omnipy Python library is designed to help develop stepwise validated (meta)data
    transformations as scalable data flows that can be incrementally designed, updated,
    and rerun as requirements or data evolve.

    To demonstrate the concept of "continuous RDM" we will use Omnipy to define and
    orchestrate Git-backed CI/CD (Continuous Integration/Continuous Delivery) data
    flows to convert ISA metadata present in ARCs into validated RO-Crate representations
    adhering to the Bioschemas convention. A RO-Crate package combines the actual
    research data with its metadata description. Downstream, this allows semantic
    interpretation by Galaxy for e.g. workflow execution as well as machine-readable
    data access and data harvesting for search engines such as FAIDARE.'
  authors: Sebastian Beier, Sveinung Gundersen, Stuart Owen
  extra_info: "The short-term goal of this project is to develop a minimum viable\
    \ prototype to show that the underlying concept of \u201Ccontinuous RDM\u201D\
    \ works. In the long-term, we aim for full integration of ISA profiles for RO-Crate.\
    \ Our approach is framework-agnostic, with Omnipy serving as a reference and proof-of-concept\
    \ but open for extensions and implementations with other frameworks.\n\nIf selected\
    \ for BH2023, our focus will be on realizing a first prototype. To achieve this,\
    \ we are looking for experts in ISA, RO-Crate, ARC, Omnipy, and metadata formats\
    \ to join our team. As an additional objective, we are also interested in exploring\
    \ the potential for connecting RO-Crates to Galaxy and would welcome expertise\
    \ in this area.\n\nBy bringing together a diverse team of experts with complementary\
    \ skills and knowledge, we believe that we can successfully develop and demonstrate\
    \ the concept of \u201Ccontinuous RDM\u201D and its potential for research data\
    \ management and interoperability."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/14
  number: null
  project_number: 14
  title: Enabling continuous RDM using Annotated Research Contexts with RO-Crate profiles
    for ISA
- abstract: "RO-Crate [1] is a lightweight method to package research outputs along\
    \ with their metadata. Bioschemas [3] provides metadata schemas to add structured\
    \ metadata to webpages on Life Science. Signposting [2] provides a lightweight\
    \ yet powerful approach to increase the FAIRness of scholarly objects.\n\nThe\
    \ combination of RO-Crates, Bioschemas and Signposting make resources easy to\
    \ navigate by machines, provide an unambiguous way for machines to access FAIR\
    \ metadata and content in a single request, and reduce content-negotiation hassle\
    \ that can give unpredictable results.\n\nThis tripartite combination is of benefit\
    \ for repositories and publishers as they can non-disruptively add FAIR Signposting\
    \ headers for machine navigation, support RO-Crate imports and align with Bioschemas\
    \ specifications, making FAIR Digital Objects achievable with existing technologies\
    \ over HTTP.\n\nFAIR tooling implementers can also benefit as they could create,\
    \ improve or integrate Signposting clients combined with RO-Crate libraries implementing\
    \ Bioschemas specifications. On its side, FAIR data implementers could support\
    \ consumption of FAIR Signposting and create Knowledge Graphs from RO-Crates.\n\
    \nWhile Bioschemas has been adapted by many repositories, the methods for its\
    \ consumption have largely been focused on discoverability. Now we focus on integrations,\
    \ such as building scholarly knowledge graphs from multiple Bioschemas sources.\n\
    \nFinally, FAIR outreach practitioners showcase uses of FAIR Signposting to navigate\
    \ and consume RO-Crates making FAIR closer to the community. This project will\
    \ continue the effort started as part of FDO2022 and FAIR-IMPACT to enable FAIR\
    \ Signposting and RO-Crate for content/metadata discovery and consumption.\n\n\
    References:\n\n 1. https://www.researchobject.org/ro-crate/ [https://www.researchobject.org/ro-crate/]\n\
    \ 2. https://signposting.org/FAIR/ [https://signposting.org/FAIR/]\n 3. https://bioschemas.org/\
    \ [https://bioschemas.org/]"
  authors: Stian Soiland-Reyes, Herbert Van de Sompel, Leyla Jael Castro
  extra_info: "* Timeline for long and short-term goals\n   \n    * Long-term: Improvement\
    \ of FAIRness for digital objects.\n      \n      \n    * Short-term: Improve\
    \ the metadata exchange between the three technologies\n      \n      \n   \n\
    \   \n * Focus during the BioHackathon\n   \n    * Add metadata markup/headers\
    \ to landing pages of at least one website\n      \n      \n    * Improve at least\
    \ one Signposting client\n      \n      \n    * Prototype a knowledge graph from\
    \ pages using any of the technologies\n      \n      \n    * Improve Bioschemas/RO-Crate\
    \ validation for at least one profile\n      \n      \n   \n   \n * Minimum number\
    \ of people to succeed\n   \n    * 5\n      \n      \n   \n   \n * Required level\
    \ of expertise/skills to participate\n   \n    * Some knowledge in JSON-LD, HTML\
    \ structured markup, HTML headers, structured metadata, Python would be helpful\n\
    \      \n      \n    * For webpage providers, their preferred programming language\n\
    \      \n      \n   \n   \n * Methodology used\n   \n    * Bring-your-own-Repository,\
    \ pair-programming, feature-driven development"
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/15
  number: null
  project_number: 15
  title: Enabling FAIR Digital Objects with RO-Crates, Signposting and Bioschemas
- abstract: 'Although Galaxy has a strong presence in fields like genomics and proteomics,
    it has yet to fully establish itself in the imaging community. Presently, efforts
    to integrate tools and create workflows for image analysis in Galaxy are scattered
    across research fields and locations. To address this issue, this project aims
    to foster collaboration among members interested in using Galaxy to improve the
    reproducibility, shareability, and reusability of scientific analysis, regardless
    of their scientific or technical background.

    This project aims to leverage the resources and expertise of Euro-BioImaging -the
    European research infrastructure that provides open access to imaging technologies,
    training, and data services-, and Simula Research Laboratory -a Norwegian non-profit
    research organization- to create a community that develops FAIR computational
    workflows for image analysis'
  authors: Beatriz Serrano-Solano, Anne Fouilloux
  extra_info: "The long-term goal is to create a solid community that thrives to create\
    \ reproducible and FAIR image analysis workflows. The short-term one is to coordinate\
    \ the efforts leveraging an event in which the stakeholders are often present.\
    \ The plan is delineated in the goals mentioned above:\n\n * Gather all the existing\
    \ resources for image analysis in Galaxy (tools in the Galaxy ToolShed, training\
    \ materials, and workflows in the WorkflowHub).\n * Create a list of tools widely\
    \ used in the image analysis field that are not yet integrated into Galaxy.\n\
    \ * Annotate the existing image analysis tools that are lacking annotations with\
    \ EDAM-Bioimaging.\n * Create a community of practice page in the Galaxy Community\
    \ Hub.\n\nWe are aiming at having the project leads working on it but with close\
    \ collaboration with the abovementioned communities present at the event (Galaxy,\
    \ EDAM-Bioimaging).\n\nWe welcome different levels of expertise: from Galaxy tool\
    \ developers to image analysis enthusiasts."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/16
  number: null
  project_number: 16
  title: Enhancing the image analysis community in Galaxy
- abstract: Integrating experimental data with publicly available resources can provide
    new insights into biological mechanisms and facilitate scientific discovery. However,
    the process is complex and time-consuming, especially when dealing with diverse
    data formats and sources. Here, we propose a modular query-based Python tool to
    integrate experimental data with existing biomedical resources, focusing on drug
    discovery. This approach employs SPARQL to send queries to different sources and
    integrates their output. Unlike the Open PHACTS project, which integrated multiple
    data sources using the RDF data model for drug discovery, we eliminate the need
    for a data dump thus overcoming the need for sustainability and updation of the
    RDF dataset. To demonstrate the utility of this approach, we will integrate transcriptomics
    data from MaayanLab with ELIXIR Core Data Resources like OpenTargets, HPA, and
    STRING, ELIXIR RIRs such as DisGeNET, ChEMBL, g:Profiler, and ELIXIR-NL resource
    WikiPathways to enrich the metadata underlying the experimental data to better
    understand its downstream utility. Wherever required, we will use the RIR BridgeDb
    to map across identifiers from various sources. The tool will assist comprehensive
    understanding of results from multiple discovery domains. Overall, with the help
    of the tool, we would improve the accuracy and reliability of drug discovery by
    enabling researchers to make informed decisions about which candidates to pursue
    and invest in based on a list of differentially expressed genes. We plan to publish
    our workflow on WorkflowHub, a registry that enables accessible and interoperable
    sharing and publishing of computational workflows for reuse.
  authors: Tooba Abbassi-Daloii, Yojana Gadiya, Egon Willighagen
  extra_info: Our project requires a minimum of 4-5 participants, including one domain/data
    expert, Python programmers, topic experts, and individuals knowledgeable in SPARQL
    and WorkflowHub. Our short-term goal is to develop a workflow for modular queries
    to identify drug candidates from differentially expressed genes. We will prioritize
    adhering to FAIR principles, ensuring accessibility, interoperability, and reproducibility.
    Our methodology involves integrating data from diverse sources and repurposing
    existing tools to create a comprehensive drug discovery tool. Our focus during
    BH 2023, if selected, would be to create and refine the workflow and ensure effective
    dissemination through platforms such as GitHub and WorkflowHub.
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/17
  number: null
  project_number: 17
  title: Extending interoperability of experimental data using modular queries across
    biomedical resources
- abstract: "Accurate chemical compound identification is crucial for multiple areas\
    \ \u2014 from safety regulations to discovering novel natural product-based drugs.\
    \ High-resolution mass spectrometry (HRMS) enables such identification in a precise\
    \ and robust manner but, in most cases, a reference spectrum is required to identify\
    \ an unknown compound. Despite recent advances in computational approaches for\
    \ spectral annotation, well-annotated experimental spectral databases remain crucial\
    \ for high-confidence compound annotations. Multiple open and commercial mass\
    \ spectral libraries exist at the moment, but there is a pressing need for the\
    \ improvement of database interoperability and unification of data representation.\n\
    \nMultiple issues must be addressed to increase the FAIRness (findability, accessibility,\
    \ interoperability, and reusability) of current spectral databases. Across the\
    \ spectral databases, there is no agreed unified data representation or data curation\
    \ protocols. Even if spectra are linked to public resources through universal\
    \ spectral identifiers (USI), it is frequently impossible to trace a spectrum\
    \ to the raw instrument data and applied spectral filtering. This project will\
    \ provide a platform to discuss and develop a streamlined workflow to create MS\
    \ reference libraries with entries linked to public data, and to facilitate library\
    \ publishing as an open resource to MassBank, GNPS, and other spectral data providers.\
    \ The groundwork includes the unified MZmine (Java) library creation workflows\
    \ for GC-EI-MS, LC-MSn, and ion mobility-enabled MS; Python-based projects like\
    \ matchms, MS2Query, mzSpecLib, and R-based MassBankR. Participants will work\
    \ on spectral quality, filtering, merging, and representation, which will greatly\
    \ influence machine learning prospects in the field by providing high-quality\
    \ reference data."
  authors: "Tom\xE1\u0161 Pluskal, Nils Hoffmann, Justin van der Hooft"
  extra_info: "* In the long term, our project aims to create a sustainable pipeline\
    \ for unified spectral database creation and community guidelines for spectral\
    \ library management and exchange. The immediate goal is to update and introduce\
    \ to the community a spectral library creation workflow.\n * We will split this\
    \ goal into smaller objectives and use a scrum-based approach for effective interaction\
    \ between developers. We intend to form sub-teams based on the specialization,\
    \ including the DevOps CI/CD pipelines and specific tools.\n * Lead developers\
    \ of MZmine (Robin Schmid, Olena Mokshyna) and matchms+MS2Query (Florian Huber,\
    \ Niek de Jonge) plan to support this project.\n * The minimum number is 5 people\n\
    \ * The project welcomes people with any level of programming skills, and we will\
    \ prepare a range of tasks with varying difficulty levels.\n * MZmine 3 is a modular\
    \ Java software built on the JavaFX GUI framework. The source code is hosted on\
    \ GitHub."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/18
  number: null
  project_number: 18
  title: FAIRification of mass spectral library creation
- abstract: "A requirement of peer reviewed publication is often the deposition of\
    \ raw data to an publicly available international data repository. Galaxy supports\
    \ upload to the EBI-European Nucleotide Archive through the ENA Upload Tool (toolshed.g2.bx.psu.edu/repos/iuc/ena_upload/ena_upload/0.6.1).\
    \ However, users are still required to have a strong working knowledge of the\
    \ ENA to navigate the necessary metadata to support an upload. Galaxy does not\
    \ host the metadata templates, requiring users to go through rounds of data upload,\
    \ test, edit (outside of Galaxy), reupload and retest before a submission to ENA\
    \ will be successful. This project proposes to make use of Galaxy\u2019s Interactive\
    \ Tools, namely Ethercalc, to support metadata editing inside of Galaxy in an\
    \ effort to streamline data submission and make Galaxy an end to end solution\
    \ for data analysis and publication."
  authors: Mike Thang, Bert Droesbeke, Gareth Price
  extra_info: 'This project has been designed to build on an existing Galaxy tool,
    Galaxy Interactive Tools and publicly available template documents from EBI-ENA.
    The short term goal of this project would be to establish access to ENA templates
    inside Interactive Tools, long term this would be enhanced through training and
    documentation, to allow more researchers to self-manage data upload to ENA.

    A medium size team of 4-8 people with knowledge of the ENA submission process,
    Galaxy and Github would be able to work F2F and virtually to achieve the project
    aims.'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/19
  number: null
  project_number: 19
  title: Galaxy ENA Upload as an Interactive Tool
- abstract: "ERGA is an international consortium of over 700 researchers from across\
    \ Europe who are committed to cataloguing eukaryotic biodiversity through the\
    \ generation of high-quality reference genomes as a response to biodiversity declines.\
    \ Development and implementation of standard procedures and bioinformatic pipelines\
    \ is essential for achieving ERGA\u2019s goal.\n\nAnnotation of reference genomes\
    \ is necessary for many downstream analyses, but tools and workflows for genome\
    \ annotation are still not ready to scale up. However, as the number of sequenced\
    \ genomes is rapidly increasing, there is a great need to develop standard, efficient\
    \ and reproducible genome annotation workflows. In this project we will develop\
    \ and implement pipelines for performing and evaluating genome annotations. For\
    \ this, we will identify appropriate pipeline components, create environments\
    \ or containers to facilitate their installation (if necessary) and embed them\
    \ into robust pipelines using a standard workflow manager such as Snakemake.\n\
    \nWe need people interested in genome annotation and with basic experience either\
    \ in genome annotation; pipeline development or tool packaging."
  authors: "J\xE8ssica G\xF3mez Garrido, Alice B. Dennis"
  extra_info: "In order to achieve all the objectives stated in our proposal, we would\
    \ like to divide the workload in at least three subgroups:\n\n * Coordination,\
    \ documentation and workflow release\n * Genome annotation\n * Evaluation of genome\
    \ annotations\n\nOur short-term objectives will be to identify the tools that\
    \ will become pipeline components and make them accessible via Conda or containers.\
    \ Next, we will need to wrap them up into reproducible and robust pipelines. Importantly,\
    \ we will daily document and release each of the achievements.\n\nLong-term goals\
    \ will be to finish and release all the developed pipelines, finish the Biohackrxiv\
    \ paper and run the pipelines on any ERGA assembled genomes. There is currently\
    \ an absence of such general tools for annotation, so we anticipate that this\
    \ tool would be widely adopted.\n\nWe need people interested in genome annotation\
    \ and with basic experience either in genome annotation; pipeline development\
    \ (I.e. with Snakemake) or tool packaging."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/20
  number: null
  project_number: 20
  title: Genome annotation workflows for the tree of life
- abstract: "ChatGPT has demonstrated the capability of machine learning in the natural\
    \ language processing (NLP) and text mining (TM) of unstructured data. While OpenAI\u2019\
    s GPT-4 works across many domains of knowledge, it is a \u201Cblack box\u201D\
    \ with details about the training data not made public. Open source resources\
    \ are available to support the TM of biomedical literature and unstructured clinical\
    \ text (e.g., clinical letters, imaging reports) to automatically identify information\
    \ required by health data researchers. These resources include rule-based TM methods,\
    \ machine learning methods involving state of the art neural-network-based techniques\
    \ (e.g., BERT, BERN2), and text corpora to test (and train) the methods. Public\
    \ corpora include annotated publication abstracts and full-texts, and unstructured\
    \ clinical text for synthetic or anonymised patients. It remains a challenge for\
    \ researchers to find the most appropriate TM resources for their use case, and\
    \ to store the identified data in a standard annotation format to maximise reuse.\n\
    \nThis project will make sense of current TM resources that are appropriate for\
    \ the health data domain, by collating them into a single catalogue and producing\
    \ a decision tree diagram to support researchers to identify the most appropriate\
    \ approach. Health data use cases contributed by project participants will be\
    \ evaluated against the decision tree and new exemplar TM pipelines will be built.\
    \ Existing TM methods will be optimised (and trained if necessary) and tested\
    \ for identifying biomedical entities of interest. The entities will be represented\
    \ using standardised annotation formats such as BioC and the Web Annotation Data\
    \ Model specification."
  authors: Tim Beck, Venkata Satagopam
  extra_info: The health data TM resources catalogue and decision tree diagram will
    be completed during BH 2023. The complexity of the methods required to support
    the use cases will determine how long the exemplars take to complete. This will
    also be influenced by the presence of an annotated corpus to validate the outputs,
    for example, the NLM provides corpora of abstracts annotated with diseases and
    drugs which could be used to validate results. We will focus on selecting use
    cases where we can validate the results (and train machine learning models if
    necessary) using existing corpora. We will continue the coordination of longer-term
    project goals through the HDFG. There is no minimum number of participants. Experience
    with TM would be an advantage, although health data domain experts are also welcome
    to provide use cases and validate results.
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/21
  number: null
  project_number: 21
  title: Health data text mining
- abstract: 'Increasing discoverability and usability of data originating from multiple
    domains of biodiversity research is still a major challenge in biodiversity informatics.
    Enabling connections between datasets or records across domains, such as sequence
    data and specimen or sample records is essential to facilitate access, provenance
    tracking and reproducibility in biodiversity research and conservation.

    Sequence data stored at the International Nucleotide Sequence Database Collaboration
    (INSDC) holds metadata that refer to its biological source (specimen or sample)
    which is described in the source feature qualifiers for sequences or in the sample
    attributes. However, these metadata are not always well-structured, hampering
    persistent and machine-readable linking to specimens and sample records in natural
    history collections and biobanks.

    In this project we aim to develop tools to facilitate linking between sequence
    data and associated specimens and/or sample records in public collections. For
    that we will build on tools previously developed by team members to derive mappings
    between sequence data and specimen or sample information, based on the datasets
    available at the Global Genome Biodiversity Network (GGBN) data portal. These
    mappings will allow the generation of machine readable links between data types
    and the enrichment of the sequence records at INSDC through the submission of
    improved annotations to the ELIXIR Contextual Data ClearingHouse.

    We expect that the tools and workflows developed within this project can then
    be applied to other datasets and therefore may further contribute to improved
    linking between sequence data and specimen information, promoting the reusability
    of data for biodiversity research.'
  authors: Joana Pauperio, Sam Leeflang, Quentin Groom
  extra_info: 'All the data we will work with is openly licensed and accessible through
    web-based HTTP APIs and downloads. We plan to do some preliminary research prior
    to the hackathon to ensure we can start the core work of the project immediately.

    This will involve identifying the GGBN records that might be easily linked. We
    can then work outward towards more difficult linking, working with records with
    less information or where the identifiers are harder to disambiguate. All the
    mappings will then be used to link records and improve current source metadata
    on the sequence records (e.g. by linking to DiSSCo identifiers).

    We would like to engage people with a broad range of skills and experience, from
    bioinformaticians, molecular biologists with knowledge on the molecular databases,
    ecologists and taxonomic experts to work on this proposal.

    A team of 6-10 people would be sufficient to work on this project.'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/22
  number: null
  project_number: 22
  title: Improved linking from sequence data to specimens and samples repositories
- abstract: "Bioschemas is a grassroots community effort to improve the FAIRness of\
    \ web-based resources in the Life sciences by defining domain-specific metadata\
    \ schemas which, when adopted, expose key metadata properties from resource records,\
    \ aiding users to find data quickly, accurately and efficiently. During the Biohackathon\
    \ Europe 2022, we focused on improving our tooling, particularly to facilitate\
    \ the Bioschemas Profile development process by automating the usage of outputs\
    \ from the Data Discovery Engine (DDE)--a tool for creating, registering and editing\
    \ schemas. Since then, we have been engaging with communities interested in updating\
    \ Bioschemas profiles and types and have updated many Bioschemas profiles. While\
    \ the process to create and update profiles is now in production, the process\
    \ to create entirely new \u2018types\u2019 leaves a glaringly missing piece in\
    \ the adoption by entirely new communities. Hence, there is a disconnect between\
    \ profiles (which can be updated by community members) and the types upon which\
    \ these profiles are built (which can require technical expertise). To improve\
    \ the accessibility and value of Bioschemas to existing and emerging communities,\
    \ we will address the issues in the Bioschemas profile and type development process,\
    \ improve the tooling and documentation around Bioschemas validation and usage,\
    \ and assist community members and resource providers in implementing or developing\
    \ Bioschemas profiles and types by actively \u2018hacking\u2019 with already identified\
    \ groups who are also submitting proposals."
  authors: Ginger Tsueng, Nick Juty, Alban Gaignard
  extra_info: This project is based on a previously successful Biohackathon project.
    The short-term goal of refining documentation and having and developing an automated
    workflow for Bioschemas types is expected to be achievable within the duration
    of the hackathon. Extensive testing and adoption of the automated workflow for
    types is expected to take place within 3 months after the hackathon, with full
    implementation by 6 months post-hackathon. Minimally, at least two people with
    programming expertise would be needed to clone and adopt the automated workflow
    for types. At least one person with no technical expertise is desired for refining
    the documentation. Tools for markup validation already exist and/or are in development,
    and at least one person with no technical expertise would be needed for testing
    these tools in a Bioschemas context. As with the previous Biohackathon, we anticipate
    engaging with members of other projects to meet the goals of this one.
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/23
  number: null
  project_number: 23
  title: Improving Bioschemas creation and community adoption through process improvements
    and tool development, and advancing compliance to FAIR standards
- abstract: "The proposed project seeks to enhance the functionality and usability\
    \ of the OpenEBench platform (https://openebench.bsc.es/), as well as foster collaboration\
    \ and engagement within the ELIXIR communities that are interested in performing\
    \ a benchmarking evaluation of tools and/or workflows using this framework.\n\n\
    Our first objective is to promote a greater sense of community participation in\
    \ benchmarking activities. To achieve this, we plan to establish connections between\
    \ OpenEBench and APICURON, which will provide users with a comprehensive overview\
    \ of their contributions to their benchmarking activities. For that, APICURON\
    \ will gather a rich set of metadata in the platform, based on Schema.org and\
    \ Bioschemas. This will enable contributors\u2019 activities to be exposed in\
    \ a more detailed view through third party systems, e.g. ORCID.\n\nOur second\
    \ objective is to encourage participation in benchmarking activities by working\
    \ on best practices and new processes for onboarding communities. These resources\
    \ will be included in the OpenEBench documentation (https://openebench.readthedocs.io/)\
    \ to make the platform more accessible for new users, especially those with less\
    \ experience in benchmarking activities. In addition, we want to help users in\
    \ understanding the results generated by OpenEBench, by creating new visualizations\
    \ and summaries for specific communities. Those available resources will be then\
    \ exposed via a visualizations gallery.\n\nOverall, our proposal seeks to strengthen\
    \ the OpenEBench platform and the ELIXIR Communities collaboration. By improving\
    \ the platform's usability and recognizing individual contributions, we hope to\
    \ encourage increased participation in benchmarking activities and foster a stronger\
    \ sense of community."
  authors: Laura Portell-Silva, Carles Hernandez-Ferrer, Adel Bouhraoua
  extra_info: OpenEBench is a constantly evolving project that relies on community
    feedback and collaboration. During the BioHackathon, we plan to gather input from
    potential users so that we can incorporate best practices for onboarding new communities,
    as well as new data visualizers for concrete scenarios. Also, we want to start
    an interconnection between APICURON and OpenEBench during the BioHackathon. Therefore,
    for the project to succeed, we would need the involvement of APICURON and ELIXIR
    communities (CAID, hCNV and others). After the BioHackathon, the work done will
    continue in some European projects such as, EuCanImage, EUCAIM and PerMedCoE.
    The level of expertise of the participants will be from front-end developers to
    help us with new data visualizers to experts in APICURON to provide us with a
    crediting service and, finally, anyone, with any level of expertise, that could
    help us with the new processes for the onboarding of new communities in OpenEBench.
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/24
  number: null
  project_number: 24
  title: Improving functionality and usability of OpenEBench for data-driven research
    in Life Sciences through Community-led efforts
- abstract: 'Galaxy offers almost 10,000 tools that are developed in different Git
    repositories.

    Furthermore, Galaxy also embraces granular implementation of software tools as
    sub-modules combined in suites. Some key examples of suites include Mothur and
    OpenMS. The decentralised development and the sub-module architecture make it
    difficult for Galaxy users to find and reuse tools, or to filter e.g. for all
    tools available for a specific research community. It may also result in Galaxy
    developers replicating effort by simultaneously wrapping new tools.

    We propose to combine preliminary work from the Freiburg Galaxy team, the Australian
    BioCommons, and the ELIXIR Tools Platform, in order to collect the available Galaxy
    tools for a target community, automatically extract their metadata (including
    Conda version, Bio.tools identifiers, and EDAM annotations), render the data as
    an interactive table on the Galaxy Hub, and put in place systems that keep the
    information up to date.

    In parallel, we will work on improving tools metadata on Bio.tools and the ToolShed,
    so that they can be interactively filtered and compared. For Bio.tools, this effort
    will include a refinement of the annotation practices, a crowdsourced community
    effort to add and curate tools, and an assessment of the impact of this effort
    on the generated Galaxy tool list for a specific Community.

    This project will directly engage with the ELIXIR Biodiversity and the emerging
    Microbiome Communities, to improve the findability, visibility, comparability,
    and accessibility of their tools.'
  authors: Paul Zierep, Johan Gustafsson, Nicola Soranzo
  extra_info: 'In the short-term, we will focus on moving the prototype to production
    by adding the required features, developing a working example, and on curating
    the Bio.tools annotations. To achieve this, a small group (~4) with basic programming
    knowledge in Python and some expertise in web development will be sufficient.
    For the curation, we will convene a larger group composed of Community champions
    (Biodiversity and Microbiome), and Tools Ecosystem experts from Bio.tools and
    EDAM.

    We will also engage with core Galaxy developers to extend the tool metadata exposed
    by the ToolShed, exploiting the recent efforts to completely refactor the ToolShed
    codebase.

    The long-term goals will be the reuse of the comprehensive Galaxy tool table by
    any Community (e.g. Single cell), and the reuse of the curation process by the
    broader Tools Ecosystem and its user community.'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/25
  number: null
  project_number: 25
  title: Increasing the findability, visibility, and impact of Galaxy tools for specialised
    scientific Communities
- abstract: 'It is common for data resources, including ELIXIR Core Data Resources,
    to connect with scientific literature as the gateway to scientific evidence, in
    support of the curation effort. The granularity of annotation is often at the
    level of the article, such as PMID or DOI, meaning that a paper is cross-referenced
    from a database entry or from some sub-annotations of the entry. This cross-reference
    is often described via terminological or ontological descriptors (e.g., molecular
    functions, cellular locations, diseases, traits) within the entry. It is only
    in rare cases that a higher granularity of the annotation is available. E.g.,
    sentence-level annotations in GeneRiF.


    In complement, literature services (e.g., JATS) and text mining communities (e.g.,
    BioC), as well as specific biological communities (e.g., TaxPub for taxonomic
    treatments) have developed standards to tentatively capture annotations directly
    or as a supplement to the published text. While annotations like Accession Number
    are trivially captured by literature services (e.g., EuropePMC, SIBiLS), more
    structured evidence (e.g., named-entities or relationships between entities) remains
    challenging for both curation-support and text mining pipelines. Further, non-textual
    publication materials (e.g., supplementary data files) have been less used by
    both curation and publication communities due to the lack of exploration tools
    and standards to process these files.'
  authors: Silvio Tosatto, Ulrike Wittig, Mihail Anton
  extra_info: "Project plan:\n\n * O1: to establish a landscape analysis of data and\
    \ services resources;\n * O2: to enhance existing standards (e.g., JATS) to better\
    \ capture curated evidence from the literature;\n * O3: to explore how literature\
    \ and crediting services (e.g., APICURON) can benefit from these new standardization\
    \ efforts.\n\nO1 should be delivered by the end of the Hackathon. O2 should be\
    \ mostly (~80%) completed by the end of the Hackathon. O3 will benefit from the\
    \ Hackathon\u2019s prototyping effort and could be completed within a year or\
    \ in a future hackathon.\n\nTimeline: A non-linear timeline could be the following:\
    \ Landscape analysis [2days], standard developments [2days], prototyping [2days].\n\
    \nLevel of expertise and population: We expect balanced contributions from two\
    \ types of profiles: biocurators (N=3-5) and data/software developers (N=3-5).\n\
    \nMethods: We plan to alternate focus group meetings and RAD development phase,\
    \ all co-ordinated by senior DevOps (Mihail Anton/SciLifeLab and Alexandre Flament/SIB)."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/26
  number: null
  project_number: 26
  title: Literature Biocuration Practices and Guidelines
- abstract: "Brokering data from producers to repositories is an integral service\
    \ for research data management platforms. However, existing tools are often technique/domain-specific\
    \ and focused on a single repository. During the BioHackathon 2022, we designed\
    \ a unified and technique/domain-specific data brokering approach for submitting\
    \ multi-omics studies to multiple specialized repositories. Briefly, an ISA-JSON\
    \ file, containing repository required metadata, is processed by an independent\
    \ upload tool that bundles credentials, data and metadata, and defines the destination\
    \ repository for each schema. Then, a multi-repository converter applies mapping\
    \ rules between ISA-JSON schemas and different repositories\u2019 models, initiating\
    \ the (meta)data submission process. Initial mappings and prototypes for BioSamples\
    \ and ENA have been made previously.\n\nDuring this BioHackathon project, we aim\
    \ to advance the development of the approach defined last year, by including other\
    \ ELIXIR and non-ELIXIR repositories, namely MetaboLights, BioStudies/ArrayExpress\
    \ and e!DAL-PGP, to cover multi-omics submission. To reinforce the broad applicability\
    \ of the approach, we will work with ISA-JSON files generated by the ARC data\
    \ structure, in addition to the ones generated by DataHub. We will also further\
    \ explore the application of stepwise validated data flows orchestrated through\
    \ Omnipy to extend the existing prototype of the converter tool. Defining requirements\
    \ for the implementation of the independent upload tool is also in scope to support\
    \ the feasibility of a streamlined brokering process."
  authors: Flora D'Anna, Rafael Andrade Buono, Zahra Waheed
  extra_info: "Focus and project plan:\n\n * Mapping of additional repositories\u2019\
    \ models to ISA-JSON schemas.\n   \n   \n * Evaluate solutions such as Omnipy\
    \ and extend the prototype.\n   \n   \n * Define requirements for the independent\
    \ upload tool.\n   \n   \n\nShort-term:\n\n * Minimum viable products for BioSamples\
    \ and ENA conversion and submission.\n   \n   \n * Proof-of-concept multi-repository\
    \ converter including the additional repositories.\n   \n   \n\nLong-term:\n\n\
    \ * Uptake of ISA-JSON as standard for multi-repository metadata submission by\
    \ data producers and repositories.\n   \n   \n * A domain-agnostic toolset that\
    \ is easy to integrate in different platforms and pipelines.\n   \n   \n * A toolset\
    \ contributed to by the repositories and open for contributions by the different\
    \ stakeholders.\n   \n   \n\nMinimum number of people: 2 software developers and\
    \ 2 data stewards. We have engaged with the stakeholders described in the collaborations.\n\
    \nExpertise: ISA-JSON, data submission to EBI-EMBL repositories and e!DAL-PGP,\
    \ coding skills (Python, Java and Javascript).\n\nMethodology: Building on BioHackathon\
    \ 2022's success, we will leverage diverse expertise of the participants and use\
    \ hands-on (pseudo)coding to achieve our development goals."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/27
  number: null
  project_number: 27
  title: Multi-Repository Data Submission using ISA-JSON
- abstract: "HYPATIA (https://hypatia.athenarc.gr/) is the Cloud infrastructure that\
    \ has been developed to support the computational needs of the ELIXIR-GR community\
    \ and the broader community of life scientists in Greece and abroad. Under the\
    \ hood, it is based on SCHEMA (https://schema.athenarc.gr/), a suite of open-source\
    \ platforms that facilitate the allocation of computational cluster resources\
    \ for scientific use. One of the key functionalities offered is an API & a UI\
    \ that enables the execution of containerized Common Workflow Language (CWL) workflows,\
    \ implementing various well-established standards, including the Global Alliance\
    \ for Genomics and Health\u2019s (GA4GH) Workflow and Task Execution Service (WES\
    \ and TES) API specifications.\n\nWorkflows are an essential tool for managing\
    \ highly complex biological data in modern life science research. Providing a\
    \ seamless and interoperable environment for executing life science workflows\
    \ is crucial for maximizing biological insight. Towards this direction, we propose\
    \ to enhance SCHEMA\u2019s platform capabilities to support additional workflow\
    \ languages such as Snakemake, Nextflow and Galaxy. In this way, data analysis\
    \ workflows can be automated, rigorous and easily reproducible. Moreover, the\
    \ use of RO-Crates will be tested in conjunction with workflow languages to facilitate\
    \ the creation of self-contained packages that include all the necessary components\
    \ o reproducing research and therefore advance scientific understanding."
  authors: Thanasis Vergoulis, Eleni Adamidi
  extra_info: 'The focus will be to adjust SCHEMA to support additional workflow languages.
    To this end, the project participants will identify and choose the most appropriate
    languages for their specific needs aiming at languages that can be easily combined
    with SCHEMA. Overall, the proposed project has the potential to provide both short-term
    and long-term benefits to the scientific community. By enhancing the capabilities
    of the SCHEMA platform and promoting research reproducibility, the project has
    the potential to advance scientific understanding and improve the efficiency and
    effectiveness of scientific research.

    It is worth to mention that (a) one of the project leads (Thanasis Vergoulis)
    has previous experience in leading a successful project in BH2021, (b) there is
    already expressed interest from two developers to participate in the project,
    and (c) developer documentation is available (https://schema.athenarc.gr/).'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/28
  number: null
  project_number: 28
  title: Providing a seamless and interoperable environment for executing life science
    workflows
- abstract: "The European Genome-phenome Archive (EGA) is a service for archiving\
    \ and sharing personally identifiable genetic and phenotypic data, while the The\
    \ Genomic Data Infrastructure (GDI) project is enabling access to genomic and\
    \ related phenotypic and clinical data across Europe. Both projects are focused\
    \ on creating federated and secure infrastructure for researchers to archive and\
    \ share data with the research community, to support further research.\n\nThis\
    \ project proposal is focusing on the data access part of the infrastructure.\
    \ The files are encrypted in the archives, using the crypt4gh standard. Currently,\
    \ there exist data access processes, where the files are either decrypted on the\
    \ server side and then transferred to the user or re-encrypted server-side and\
    \ provided to the user in an outbox.\n\nHtsget as a data access protocol also\
    \ allows access to parts of files, but there\u2019s currently no production-level\
    \ client tools that support access to encrypted data. Our goal is to create a\
    \ client tool that can access encrypted data over the htsget protocol. It should\
    \ also work with the GA4GH Passport and Visa standard so we can then enhance the\
    \ security of our data access interfaces. We will also modify the htsget reference\
    \ implementation server (https://github.com/ga4gh/htsget-refserver) as required\
    \ to support the aforementioned standards. Finally, there will be an effort to\
    \ implement this feature in already existing tools, like samtools and IGV."
  authors: Johan Viklund, Stefan Negru, Dimitrios Bampalikis
  extra_info: "* Short-term we want to have a CLI tool that can retrieve encrypted\
    \ data over htsget and decrypt it locally.\n * Medium-term we want to add support\
    \ for range requests and\n * Long-term to have this work seamlessly in for example\
    \ samtools, IGV and galaxy.\n * Depending on the number of people joining the\
    \ project, the focus will vary between * Creating command line interface that\
    \ will be able to access retrieve and decrypt the data, and\n    * expanding known\
    \ and widely used tools to support this functionality.\n   \n   \n * The minimum\
    \ number of people required for the project to achieve one of the above goals,\
    \ is approximately 5.\n * Experience with programming and preferably golang is\
    \ welcome, however, input related to the user experience would be appreciated.\n\
    \ * We will use parts of the scrum methodology, analyzing the requirements in\
    \ epics and breaking them down to user stories."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/29
  number: null
  project_number: 29
  title: Secure data-out API - enabling encrypted htsget transactions
- abstract: "Research data management is becoming increasingly important in the scientific\
    \ community. A critical challenge in this field is making research data FAIR (findable,\
    \ accessible, interoperable and reusable, Wilkinson et al. 2016). Metadata plays\
    \ a vital role in this challenge as it allows researchers to accurately understand\
    \ and recreate experiments. To tackle this challenge, various approaches are being\
    \ taken towards this goal, including the development of domain-overarching and\
    \ domain-specific standards.\n\nIn the plant science community, multiple domain-specific\
    \ minimal information standards have been developed, such as MIAPPE, MIAME and\
    \ MINSEQE. These standards are designed to describe specific types of experiments.\
    \ Recently, a minimal standard for single-cell experiments, minSCe (minimal information\
    \ about a single-cell experiment), has been introduced (F\xFCllgrabe et al. 2020).\
    \ However, it is not yet widely used. While minimal standards are important, they\
    \ are only part of the solution. The use of controlled vocabularies and ontology\
    \ terms is also essential. Ontology terms have a persistent identifier, an expressive\
    \ name and a curated definition. Using these terms enables different researchers\
    \ to understand and recreate annotated experiments. In this project, we propose\
    \ to expand biological and technical metadata schema as well as ontologies for\
    \ single-cell experiments across domains with a focus on transcriptomics. This\
    \ will facilitate the sharing and reuse of single-cell data and promote collaboration\
    \ among researchers in different domains. Our goal is to improve data management\
    \ practices and enhance the reproducibility of single-cell research."
  authors: "Hannah D\xF6rpholz, Stefania Giacomello, Naveed Ishaque"
  extra_info: "Our project is built on our expertise in the single-cell omics field,\
    \ which is part of the larger ELIXIR community, as well as on our experiences\
    \ working with plant-related ontologies. Both topics have previously been worked\
    \ on during the BioHackathon Germany. By combining our knowledge and making use\
    \ of available public datasets such as from the Single-Cell Expression Atlas and\
    \ the Human Cell Atlas, we expect to be able to reach our primary goals of creating\
    \ a minSCe ontology and testing the model for different datasets. On site, we\
    \ would also like to consult the ISA community regarding the conversion from the\
    \ minSCe MAGE-tab format to ISA, in order to work towards our goal of creating\
    \ a robust mapping between the two formats.\n\nParticipants:\n\n * required: 5\n\
    \   \n   \n * maximum: 10\n   \n   \n\nParticipant minimum requirements: knowledge\
    \ about ISA, MAGE-tab, minSCe, ontologies (OWL, OBO), plant sciences"
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/30
  number: null
  project_number: 30
  title: Standards and ontologies for single cell experiments
- abstract: 'Wastewater-Based Epidemiology (WBE) began to flourish in 2001 and was
    initially used for the detection of illegal drugs. Historically though, around
    the 1950''s WBE was implemented for the detection of infectious diseases, when
    the first studies to detect poliovirus and enteroviruses in sewage samples were
    conducted. These studies were based on the fact that since viruses cannot grow
    outside of host cells, they lose the ability to evolve in wastewater, and thus
    the concentration values that were found in sewages are related to those that
    were initially egested by the population. During the COVID-19 pandemic WBE became
    a community-wide monitoring tool which provided real-time data concerning both
    public health status, environmental monitoring as well as food safety. Moreover,
    in addition to the traditional wastewater surveillance metrics that rely on biochemical
    indicators, the pandemic led to the increased use of high-throughput sequencing
    data on wastewater samples. This led to a number of key challenges and questions
    in the field, ranging from the data capture efforts through biosensors, until
    the data management and data analysis efforts

    The main goal of this project will be to define a framework for addressing specific
    health policy-related questions based on multi-modal wastewater surveillance,
    including a critical review on the applicable standards for (meta)data. The effort
    will build on the efforts of the relevant BH2022 project on wastewater surveillance,
    as well as on the collective expertise of the ELIXIR COVID19 Wastewater Surveillance
    Working Group. Ultimately, the proposed framework will be demonstrated using existing
    publicly available data.'
  authors: Fotis Psomopoulos, Amy Fitzpatrick, Matthew Wade
  extra_info: "Long-term goals\n\n * This is already an activity that the WG is working\
    \ on. The BH project will help push this further and make quantifiable progress,\
    \ while engaging with a wider community.\n\nShort term goals\n\n * Identify and\
    \ short-list relevant standards\n * Implement a proof-of-concept synthetic dataset\
    \ process for Wastewater surveillance\n\nRequired expertise\n\n * Researchers\
    \ active in national wastewater surveillance efforts, experts in genomic data\
    \ production and management - including metadata standards, bioinformaticians\
    \ including people who are running wastewater surveillance pipelines\n * workflow\
    \ expertise (python, snakemake, nextflow), WES expertise, R/Python/HTML/CSS/Javascript\
    \ developers\n * pilot website, UI experience, Data Visualization\n\nMethodology\
    \ to be used\n\n * Survey existing efforts and resources in order to collate information\n\
    \ * Rely on existing efforts under ELIXIR and the Synthetic data community, in\
    \ order to defined specifications and requirements"
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/31
  number: null
  project_number: 31
  title: Standards for a multimodal data wastewater surveillance process
- abstract: "Systems biology (SB) is a new ELIXIR Community, utilising different ELIXIR\
    \ resources, such as the Training eSupport System (TeSS) and bio.tools, a registry\
    \ of software tools and data resources for life sciences. One of the main initial\
    \ objectives of the SB Community is to create a SB-themed domain hosted by TeSS,\
    \ encompassing SB-related ELIXIR services and events, in a fully automated way.\
    \ Most content in TeSS is sourced through automated aggregation (\u201Cscraping\u201D\
    ) of external sources containing resources marked up with semantic metadata, like\
    \ Bioschemas. Currently, TeSS cannot recognize references to bio.tools identifiers\
    \ from a Bioschemas-annotated resource, so the number of resources linked to bio.tools\
    \ is relatively low. In this project, TeSS\u2019 Bioschemas parser will be extended\
    \ to recognize bio.tools identifier references, and documentation produced advising\
    \ training resource maintainers how they can add these references to their Bioschemas\
    \ markup. In collaboration with TeSS and bio.tools, we will focus on selected\
    \ SB disciplines from the priority areas of the SB Community to integrate and\
    \ cross-link related ELIXIR products - training events, training materials, computational\
    \ and bioinformatics tools, databases and services from the bio.tools registry.\
    \ This will be achieved using suitable ontologies identified by the SB community\
    \ and by careful curation of SB-related materials. We aim to extend this work\
    \ to other ELIXIR products such as lists of trainers, related ELIXIR Innovation\
    \ and Industry events and publications. This will serve as a pilot project leading\
    \ to broader integration with other SB disciplines, and will be of interest to\
    \ several other ELIXIR Communities."
  authors: Barbara Szomolay, Brane Leskosek, Herve Menager
  extra_info: "* The short-term goal is to conduct a pilot study at the Biohackathon,\
    \ the long-term goal is to extend the automated frame-work to other SB-related\
    \ ELIXIR domains and services.\n * (1) Adapting ontologies and explore ontology\
    \ mappings (e.g., between EDAM and SBO), to annotate SB-related products by a\
    \ set of controlled and relational vocabularies. (2) Using selected SB disciplines\
    \ and related TeSS and bio.tools products (training events, training materials,\
    \ computational, bioinformatics tools, databases, services), to integrate TeSS\
    \ and bio.tools by extending TeSS\u2019 Bioschemas parser. We will aim to explore:\
    \ (3) Compliance with FAIR principles. (4) Extension to other ELIXIR resources.\n\
    \ * The preparation for the Biohackathon will start well before November to ensure\
    \ we have a balanced and well-prepared team of curators and software developers,\
    \ a minimum of 2-3 from both groups.\n * We will leverage expertise of both curators\
    \ and software developers, by alternating group meetings and the actual development\
    \ of the project."
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/32
  number: null
  project_number: 32
  title: Synergising ELIXIR Resources for Training in Systems Biology
- abstract: "We would like to propose the establishment of a \"BioHackCloud\" (BHC)\
    \ - a cloud-based infrastructure for the federated analysis of biological/biomedical\
    \ data based on Global Alliance for Genomics and Health (GA4GH) standards and\
    \ other relevant open community standards. The ELIXIR Cloud & AAI GA4GH Driver\
    \ Project-run \u201CELIXIR Cloud\u201D infrastructure would serve as the initial\
    \ BHC. It is now at a level of maturity that it can be used experimentally for\
    \ executing CWL and Snakemake workflows, as well as running individual data-intensive\
    \ tasks on a network of compute centers within ELIXIR.\n\nThe BHC will be offered\
    \ to interested BioHackathon participants, with BHC project participants providing\
    \ training and support for the realization of individual use cases (e.g., construction\
    \ of API calls, modification of workflows, addition of features and integrations\
    \ to the individual services). Feasibility will be evaluated on a case-by-case\
    \ basis, but where use cases cannot be realized with the current infrastructure,\
    \ future support of these use cases will be considered for the BHC roadmap.\n\n\
    Next to providing support for other participants, another main goal for the BHC\
    \ project is the integration with other relevant services on the basis of open\
    \ community standards. In particular, for this hackathon we will focus on furthering\
    \ the interoperability with Microsoft\u2019s native TES on Azure implementation\
    \ (https://github.com/microsoft/ga4gh-tes). But integration of other community\
    \ standards (e.g., RO-Crate) and implementations (e.g., WorkflowHub, Dockstore,\
    \ BioContainers) is also possible, depending on participants\u2019 interests."
  authors: Alexander Kanitz, Anurag Gupta, Matt McLoughlin
  extra_info: 'If accepted, we will reach out to the leads of other project leads
    early (at least a month in advance) to get an understanding of possible use cases
    that we could support with the BHC and to prepare accordingly. For the integration
    goals, a project board with detailed issues will be prepared, and based on available
    participants and current needs, a common development theme with realistic milestones
    for the event will be set on Day 1.

    Requirements for use cases which we can currently not support will be used to
    draft a BHC roadmap on Day 5, to be addressed at or in preparation of future events.
    To support use cases and drive development, we estimate that we would need at
    least 6 contributors (the more, the better) with different skill sets (e.g., coding
    in Python, Javascript/Typescript; devops/Kubernetes; workflows; containers; data
    analysis) and varying degrees of experience.'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/33
  number: null
  project_number: 33
  title: The BioHackathon Cloud
- abstract: "The Training SPLASH project aims to establish a digital environment representing\
    \ a \u201Cone-stop-shop\u201D for ELIXIR Training Platform (ETrP) services in\
    \ order to increase its visibility, accessibility and usage and enable more participation\
    \ within and outside the ELIXIR community. The ETrP has several successful training\
    \ products, such as TeSS, the Train-the-Trainer programme, the FAIR training project,\
    \ relevant papers, a training operational handbook containing guidelines etc.\
    \ We aim to transform access to these resources by creating a single entry point\
    \ for trainers, trainees, training providers, funders, training developers, and\
    \ the other ELIXIR Platforms and Communities. SPLASH will adopt a user-centric\
    \ approach to present the information sought in a ready-to-use format that will\
    \ enable the packaging and visibility of the different training products, using\
    \ the successful model of the RDMkit, and the ELIXIR Toolkit theme. The created\
    \ digital resource will be connected with the ELIXIR website and TeSS with the\
    \ possibility to connect to other services in the future. We aim to establish\
    \ a diverse team composed of web developers, UX designers and content providers.\
    \ An additional benefit of this project is to foster a collaborative environment\
    \ for knowledge exchange, enabling members of the ETrP to continue updating the\
    \ website (content and more) beyond the hackathon. The ultimate goal of SPLASH\
    \ is to create a minimal viable version of this digital environment that will\
    \ be publicly available by the end of the hackathon."
  authors: Alexia Cordana, Mihail Anton, Alexander Botzki
  extra_info: The short-term goal of the Training SPLASH project is to establish a
    digital resource as a minimal viable product during the BioHackathon 2023. This
    initial version of the digital resource will be extended during the next ELIXIR
    Training Platform Programme 2024-2028. We foresee a preparatory phase before the
    Biohackathon which includes having an initial wireframe and sufficient content
    readily available (content curation, sub pages etc) as well as the provisioning
    of a GitHub-hosted framework based on the ELIXIR Toolkit Theme template. The project
    should have a minimum of five people, with content expertise in ELIXIR training
    resources and technical expertise around the GitHub, Jekyll and UX design.
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/34
  number: null
  project_number: 34
  title: Training SPLASH
- abstract: 'We propose developing a cross-platform library for researchers to sign
    and publish Nanopublications. Nanopublication is a protocol to publish small pieces
    of information in a machine-readable format (the Resource Description Framework),
    Nanopublications are signed using a private key linked to the user''s ORCID for
    authentication and traceability, then published to a decentralized network of
    Nanopublications servers.


    Nanopublications are commonly used in biomedical and semantic web communities
    for publishing research-related data and metadata in a free, open, and trusted
    platform. There is currently an official implementation of the Nanopublication
    signing process in Java, and we have been working on a Python implementation,
    but there is is no JavaScript implementation that can perform signing in the browser
    yet, which would enable developers to implement the signing process on the web
    without the need for hosting a server.


    We aim to solve this problem by developing a Rust library that can be compiled
    to work on any platform, including in the browser with WebAssembly. In addition,
    we will define bindings and publish libraries to packages registries for popular
    languages, such as JavaScript and Python.

    This solution will enable developers to easily sign and publish Nanopublications
    from the browser, and will eliminate the need for maintaining and updating multiple
    versions for different languages, which requires extensive testing to ensure all
    cases are covered.

    We believe that this project has the potential to improve access to technologies
    helping to build systems complying with the FAIR principles (Findable, Accessible,
    Interoperable, Reusable).'
  authors: Vincent Emonet, Shashank Chakravarthy
  extra_info: 'In the short-term, by the end of the Biohackathon, we hope to have
    a proof of concept of a Rust library that compiles to a JavaScript module, published
    to a public git repository with all the documentation required to reuse and maintain
    the project. In the long term, after the hackathon we plan to integrate this signing
    component to the nanopub-js web libraries, and create bindings for python and
    ruby.

    A minimum of 2 to 3 people should be enough for the project to succeed, but it
    would gain from having more people joining and sharing their ideas and experiences.

    People with experience in programming with any language are welcome to join us
    discovering the new tools and paradigms we will explore.

    We will use a public git repository to collaborate and publish the code. We plan
    to use cargo with wasm-pack to compile the code and documentation.'
  link: https://github.com/elixir-europe/bioHackathon-projects-2023/tree/master/projects/35
  number: null
  project_number: 35
  title: 'Write once, run everywhere: exploring the use of Rust and WebAssembly to
    implement the Nanopublication signing protocol.'
